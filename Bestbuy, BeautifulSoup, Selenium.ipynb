{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a1ede5",
   "metadata": {},
   "source": [
    "## Get Selenium to work on system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca84708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Get on Google\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(4)\n",
    "driver.get('https://google.com')\n",
    "\n",
    "# Search on \"askew\"\n",
    "time.sleep(1)\n",
    "input = driver.find_element(By.CSS_SELECTOR, 'textarea[title=\"Search\"]')\n",
    "input.send_keys('askew\\n')\n",
    "\n",
    "time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14897d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search on \"google in 1998\"\n",
    "time.sleep(4)\n",
    "driver.get('https://google.com')\n",
    "input = driver.find_element(By.CSS_SELECTOR, 'textarea[title=\"Search\"]')\n",
    "input.send_keys('google in 1998\\n')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d574f",
   "metadata": {},
   "source": [
    "## Write a script that goes to bestbuy.com, \n",
    "clicks on Deal of the Day, reads how much time is left for the Deal of the Day and prints the remaining time to screen (console), clicks on the Deal of the Day (the actual product), clicks on its reviews, and saves the resulting HTML to local hard drive as \"bestbuy_deal_of_the_day.htm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb2a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "bestBuy_url = 'https://www.bestbuy.com/'\n",
    "time.sleep(5)\n",
    "bestBuy_page = requests.get(bestBuy_url)\n",
    "bestBuy_soup = BeautifulSoup(bestBuy_page.text, 'html.parser')\n",
    "\n",
    "time.sleep(4)\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(4)\n",
    "\n",
    "# Go to bestbuy\n",
    "driver.get('https://www.bestbuy.com/')\n",
    "# Click on deal of the day\n",
    "deal_of_day = driver.find_element(By.XPATH, '//a[text()=\"Deal of the Day\"]')\n",
    "deal_of_day.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f503a17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining time: 07 hours, 46 minutes, 37 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get the ul which includes the hours, minutes, and seconds\n",
    "time_ul = driver.find_element(By.CSS_SELECTOR, 'ul[id=\"countdown\"]')\n",
    "\n",
    "# Find all \"li\" that contains hours, minutes, seconds\n",
    "time_li = time_ul.find_elements(By.CSS_SELECTOR, 'li:not(.timesep)')\n",
    "\n",
    "countdown_time = {'hours': '', 'minutes': '', 'seconds': ''}\n",
    "all_spans = []\n",
    "\n",
    "for li in time_li:\n",
    "    # Spans which have class name that includes \"cdnumber\" contains the numbers\n",
    "    span = li.find_element(By.CSS_SELECTOR, 'span.cdnumber')\n",
    "    all_spans.append(span.text)  # Append the text of the span to the all_spans list\n",
    "\n",
    "# Print the remaining time\n",
    "if len(all_spans) == 3:\n",
    "    countdown_time['hours'] = all_spans[0]\n",
    "    countdown_time['minutes'] = all_spans[1]\n",
    "    countdown_time['seconds'] = all_spans[2]\n",
    "    print(f\"Remaining time: {countdown_time['hours']} hours, {countdown_time['minutes']} minutes, {countdown_time['seconds']} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c948f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the deal \n",
    "deal_product = driver.find_elements(By.CSS_SELECTOR, 'a.wf-offer-link.v-line-clamp')\n",
    "\n",
    "if deal_product:\n",
    "    deal_product[0].click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf55aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Click on \"see all customer reviews\"\n",
    "reviews = driver.find_element(By.XPATH, '//a[text()=\"See All Customer Reviews\"]')\n",
    "reviews.click()\n",
    "time.sleep(3)\n",
    "\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Save the html into current directory\n",
    "current_working_directory = os.getcwd()\n",
    "path = os.path.join(current_working_directory)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "html_path = os.path.join(path, \"bestbuy_deal_of_the_day.html\")\n",
    "\n",
    "# Save the page source to a file, which contains the reviews\n",
    "with open(html_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(page_source)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcdd04",
   "metadata": {},
   "source": [
    "## Write a script that goes to lavazzausa.com, rejects all cookies, then clicks on \"Products\", then on \"Capsule coffee machines\", save the resulting page to the file \"lavazza.htm\", and close the browser.  Subsequently write code that opens the saved \"lavazza.htm\" file and find the original price of the \"Classy Plus Bundle\" and prints it to screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7252fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "time.sleep(4)\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(4)\n",
    "\n",
    "# Go to lavazzausa.com\n",
    "driver.get('https://www.lavazzausa.com/en')\n",
    "\n",
    "# Reject cookies\n",
    "reject_cookies = driver.find_element(By.CSS_SELECTOR, 'div[id=\"consent_prompt_reject\"]')\n",
    "reject_cookies.click()\n",
    "time.sleep(3)\n",
    "    \n",
    "# Click on products\n",
    "products = driver.find_element(By.CSS_SELECTOR, 'a[id=\"PRODUCTS\"]')\n",
    "products.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Click on Capsule coffee machines\n",
    "Capsule_coffe_machine = driver.find_element(By.XPATH, '//a[text()=\"Capsule coffee machines\"]')\n",
    "Capsule_coffe_machine.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Save html to current directory\n",
    "page_source_coffee = driver.page_source\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "path = os.path.join(current_working_directory)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "html_path_coffee = os.path.join(path, \"lavazza.html\")\n",
    "\n",
    "# Save the page source to a file\n",
    "with open(html_path_coffee, 'w', encoding='utf-8') as file:\n",
    "    file.write(page_source_coffee)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f42c1",
   "metadata": {},
   "source": [
    "## write code that opens the saved \"lavazza.htm\" file and find the original price of the \"Classy Plus Bundle\" and prints it to screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec01d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original price for Classy Plus Bundle is $300.75\n"
     ]
    }
   ],
   "source": [
    "with open(html_path_coffee, 'r', encoding='utf-8') as file:\n",
    "    html = file.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Locate h2 which contains classy plus bundle\n",
    "    h2 = soup.find(lambda tag: tag.name == \"h2\" and tag.text.strip() == \"Classy Plus Bundle\")\n",
    "    if h2:\n",
    "        # p is the child of h2\n",
    "        pricing_p = h2.find_next('p', class_='lvz-product-card__pricing')\n",
    "        if pricing_p:\n",
    "            # Find the span that has old price\n",
    "            old_price_span = pricing_p.find('span', class_='lvz-product-card__pricing--old')\n",
    "            if old_price_span:\n",
    "                old_price = old_price_span.text.strip()\n",
    "                print(\"Original price for Classy Plus Bundle is\", old_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ee83b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
